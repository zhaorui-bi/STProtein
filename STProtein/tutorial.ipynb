{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import os\n",
    "import torch\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import warnings\n",
    "# from model.train import train_SMART\n",
    "from model.utils import fix_seed\n",
    "\n",
    "fix_seed(2025)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "# Environment configuration. SpatialGlue pacakge can be implemented with either CPU or GPU. GPU acceleration is highly recommend for imporoved efficiency.\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "file_fold = '/data/hulei/ZhaoruiJiang/Data/SpatialGlue/'\n",
    "adata_omics1 = sc.read_h5ad(file_fold + 'Dataset1_Mouse_Spleen1/adata_RNA.h5ad')\n",
    "adata_omics2 = sc.read_h5ad(file_fold + 'Dataset1_Mouse_Spleen1/adata_ADT.h5ad')\n",
    "adata_omics1.var_names_make_unique()\n",
    "adata_omics2.var_names_make_unique()\n",
    "test_adata_omics1 = sc.read_h5ad(file_fold + 'Dataset2_Mouse_Spleen2/adata_RNA.h5ad')\n",
    "test_adata_omics2 = sc.read_h5ad(file_fold + 'Dataset2_Mouse_Spleen2/adata_ADT.h5ad')\n",
    "test_adata_omics1.var_names_make_unique()\n",
    "test_adata_omics2.var_names_make_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.utils import pca\n",
    "from model.utils import clr_normalize_each_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization\n",
    "sc.pp.highly_variable_genes(adata_omics1, flavor=\"seurat_v3\", n_top_genes=3000)\n",
    "sc.pp.normalize_total(adata_omics1, target_sum=1e4)\n",
    "sc.pp.log1p(adata_omics1)\n",
    "sc.pp.highly_variable_genes(test_adata_omics1, flavor=\"seurat_v3\", n_top_genes=3000)\n",
    "sc.pp.normalize_total(test_adata_omics1, target_sum=1e4)\n",
    "sc.pp.log1p(test_adata_omics1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_omics2 = clr_normalize_each_cell(adata_omics2)\n",
    "# sc.pp.log1p(adata_omics2)\n",
    "test_adata_omics2 = clr_normalize_each_cell(test_adata_omics2)\n",
    "# sc.pp.log1p(test_adata_omics2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_omics1_high = adata_omics1[:, adata_omics1.var['highly_variable']]\n",
    "adata_omics1.obsm['feat'] = pca(adata_omics1_high, n_comps=adata_omics2.n_vars-1)\n",
    "\n",
    "test_adata_omics1_high = test_adata_omics1[:, test_adata_omics1.var['highly_variable']]\n",
    "test_adata_omics1.obsm['feat'] = pca(test_adata_omics1_high, n_comps=test_adata_omics2.n_vars-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_omics2 = adata_omics2[adata_omics1.obs_names].copy() \n",
    "adata_omics2.obsm['feat'] = pca(adata_omics2, n_comps=adata_omics2.n_vars-1)\n",
    "test_adata_omics2 = test_adata_omics2[test_adata_omics1.obs_names].copy() \n",
    "test_adata_omics2.obsm['feat'] = pca(test_adata_omics2, n_comps=test_adata_omics2.n_vars-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The graph contains 7704 edges, 2568 cells.\n",
      "3.0000 neighbors per cell on average.\n",
      "The graph contains 7704 edges, 2568 cells.\n",
      "3.0000 neighbors per cell on average.\n",
      "The graph contains 8304 edges, 2768 cells.\n",
      "3.0000 neighbors per cell on average.\n",
      "The graph contains 8304 edges, 2768 cells.\n",
      "3.0000 neighbors per cell on average.\n"
     ]
    }
   ],
   "source": [
    "from model.utils import Cal_Spatial_Net\n",
    "\n",
    "Cal_Spatial_Net(adata_omics1, model=\"KNN\", n_neighbors=3)\n",
    "Cal_Spatial_Net(adata_omics2, model=\"KNN\", n_neighbors=3)\n",
    "Cal_Spatial_Net(test_adata_omics1, model=\"KNN\", n_neighbors=3)\n",
    "Cal_Spatial_Net(test_adata_omics2, model=\"KNN\", n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distances calculation completed!\n",
      "The data use feature 'feat' contains 3340 mnn_anchors\n",
      "distances calculation completed!\n",
      "The data use feature 'feat' contains 4298 mnn_anchors\n"
     ]
    }
   ],
   "source": [
    "from model.utils import Mutual_Nearest_Neighbors\n",
    "anchors1, positives1, negatives1 = Mutual_Nearest_Neighbors(adata_omics1, key=\"feat\", n_nearest_neighbors=4,\n",
    "                                                            farthest_ratio=0.6)\n",
    "anchors2, positives2, negatives2 = Mutual_Nearest_Neighbors(adata_omics2, key=\"feat\", n_nearest_neighbors=4,\n",
    "                                                            farthest_ratio=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor(adata_omics2.X).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (train.py, line 14)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m/opt/miniforge/envs/STAligner/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3577\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0;36m  Cell \u001b[0;32mIn[11], line 1\u001b[0;36m\n\u001b[0;31m    from model.train import train_STProtein\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m/data/hulei/ZhaoruiJiang/STP/model/train.py:14\u001b[0;36m\u001b[0m\n\u001b[0;31m    model = STProtein(hidden_dims=[x1.shape[1], emb_dim],Conv_Encoder,Conv_Decoder)\u001b[0m\n\u001b[0m                                                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "from model.train import train_STProtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 136.75it/s]\n"
     ]
    }
   ],
   "source": [
    "out, model = train_STProtein(adata = adata_omics1,\n",
    "                  ground_truth= torch.FloatTensor(adata_omics2.X),\n",
    "                  feature_key=\"feat\",\n",
    "                  edge_key=\"edgeList\",\n",
    "                  weights=[1, 1],\n",
    "                  n_epochs=1000,\n",
    "                  weight_decay=0.001\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model.model import SMART,SAGEConv_Encoder,SAGEConv_Decoder\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def train_STProteinv2(adata, ground_truth ,triplet_samples, feature_key=\"feat\", edge_key=\"edgeList\", weights=None,emb_dim=64, n_epochs=500,\n",
    "               lr=0.0001,weight_decay=1e-5,device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')):\n",
    "    x1, edge_index1 = torch.FloatTensor(adata.obsm[feature_key]), torch.LongTensor(adata.uns[edge_key])\n",
    "    emb_dim = ground_truth.shape[1]\n",
    "    target = ground_truth.to(device)\n",
    "    print(x1)\n",
    "    \n",
    "    print(edge_index1)\n",
    "    anchors1, positives1, negatives1 = triplet_samples\n",
    "    print(x1.shape)\n",
    "    hidden_dims=[x1.shape, emb_dim]\n",
    "    print(hidden_dims)\n",
    "    model = SMART(hidden_dims=[x1.shape[1], emb_dim])\n",
    "\n",
    "    x1, edge_index1= x1.to(device), edge_index1.to(device)\n",
    "    model.to(device)\n",
    "    \n",
    "    n_epochs = n_epochs\n",
    "    loss_list = []\n",
    "    w1, w2 = weights\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr,weight_decay=weight_decay)\n",
    "    \n",
    "    for epoch in tqdm(range(1, n_epochs + 1)):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        z, x1_rec= model(x1, edge_index1)\n",
    "    \n",
    "        anchor_arr1 = x1_rec[anchors1,]\n",
    "        positive_arr1 = x1_rec[positives1,]\n",
    "        negative_arr1 = x1_rec[negatives1,]\n",
    "    \n",
    "        triplet_loss = torch.nn.TripletMarginLoss(margin=1, p=2, reduction='mean')\n",
    "        tri_output1 = triplet_loss(anchor_arr1, positive_arr1, negative_arr1)\n",
    "\n",
    "    \n",
    "        loss = w1 * F.mse_loss(x1, x1_rec) + w2*tri_output1 + w1*F.mse_loss(target, z)\n",
    "        loss_list.append(loss.item())\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        optimizer.step()\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    x1, edge_index1 = x1.to(device), edge_index1.to(device)\n",
    "    z, x1_rec = model(x1, edge_index1)\n",
    "\n",
    "    return z, model\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4073e+00,  2.4436e+00, -1.7743e-01,  ...,  1.5488e+00,\n",
      "          1.4655e-01,  1.3487e+00],\n",
      "        [ 2.7535e+00, -5.1512e-01, -6.2535e-01,  ...,  1.3381e-02,\n",
      "         -2.6619e+00, -7.3983e-02],\n",
      "        [ 3.6504e+00,  1.7775e+00, -1.8608e+00,  ..., -1.2904e+00,\n",
      "         -5.0396e-01, -1.9837e-01],\n",
      "        ...,\n",
      "        [-5.1598e+00, -9.6904e-01, -1.9860e+00,  ...,  1.2161e-01,\n",
      "         -8.0446e-01, -7.5742e-01],\n",
      "        [ 1.5710e+00, -9.7967e-01, -8.6028e-01,  ..., -1.5448e+00,\n",
      "         -2.4997e+00,  2.2396e+00],\n",
      "        [-2.0188e+00, -2.1807e-03, -1.5388e+00,  ..., -6.4205e-01,\n",
      "          1.5537e+00, -1.5805e+00]])\n",
      "tensor([[   0,    0,    0,  ..., 2567, 2567, 2567],\n",
      "        [2330, 1190, 2125,  ..., 1256, 1371, 1983]])\n",
      "torch.Size([2568, 20])\n",
      "[torch.Size([2568, 20]), 21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:11<00:00, 89.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# out, model = train_STProteinv2(adata = adata_omics1,\n",
    "#                   ground_truth= torch.FloatTensor(adata_omics2.X),\n",
    "#                   triplet_samples=(anchors1, positives1, negatives1),\n",
    "#                   feature_key=\"feat\",\n",
    "#                   edge_key=\"edgeList\",\n",
    "#                   weights=[1, 1],\n",
    "#                   n_epochs=1000,\n",
    "#                   weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9201,  0.6181,  1.0360,  ...,  0.0499,  0.0829,  0.4687],\n",
       "        [ 1.2642,  0.8110,  1.4424,  ...,  0.1793, -0.0323,  0.5874],\n",
       "        [ 1.2289,  0.6098,  1.0697,  ...,  0.0665,  0.1847,  0.5152],\n",
       "        ...,\n",
       "        [ 0.2237,  1.1503,  0.8767,  ...,  0.2778,  0.3653,  0.8861],\n",
       "        [ 0.6627,  0.7835,  1.2358,  ...,  0.2099,  0.3569,  0.4614],\n",
       "        [ 0.3432,  0.5640,  0.7524,  ...,  0.0936,  0.2047,  0.3281]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_1 = torch.FloatTensor(adata_omics2.X).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8446, 0.6563, 1.6487,  ..., 0.2694, 0.3722, 0.5872],\n",
       "        [0.8021, 0.7874, 1.6377,  ..., 0.2557, 0.3282, 0.4385],\n",
       "        [0.9648, 0.6843, 1.7725,  ..., 0.3220, 0.3028, 0.6643],\n",
       "        ...,\n",
       "        [0.5764, 0.7217, 0.7081,  ..., 0.3089, 0.2882, 0.4778],\n",
       "        [1.0276, 0.8202, 1.3457,  ..., 0.1555, 0.2471, 0.6598],\n",
       "        [0.8590, 0.8590, 0.9274,  ..., 0.2703, 0.0912, 0.6825]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1268, device='cuda:0', grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "F.mse_loss(target_1, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_x1, test_edge_index1 = torch.FloatTensor(test_adata_omics1.obsm[\"feat\"]), torch.LongTensor(test_adata_omics1.uns[\"edgeList\"])\n",
    "test_z, test_out = model(test_x1.to(device), test_edge_index1.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7102,  0.6781,  1.0333,  ...,  0.2398,  0.2326,  0.4020],\n",
       "        [ 1.0262,  0.2326,  0.7908,  ..., -0.2600, -0.0425,  0.1531],\n",
       "        [ 0.3880,  1.1827,  1.2729,  ...,  0.8883,  0.5605,  0.8280],\n",
       "        ...,\n",
       "        [ 0.9790,  0.4583,  0.9958,  ..., -0.0115,  0.1313,  0.0965],\n",
       "        [ 0.5296,  0.6493,  0.8867,  ...,  0.0662,  0.1503,  0.4268],\n",
       "        [ 0.3977,  0.9528,  1.1948,  ...,  0.2197,  0.2451,  0.6287]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_2 = torch.FloatTensor(test_adata_omics2.X).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2229, device='cuda:0', grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.mse_loss(target_2, test_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9200578 ,  0.6180627 ,  1.0360086 , ...,  0.04990932,\n",
       "         0.08289612,  0.4687003 ],\n",
       "       [ 1.2642105 ,  0.8109873 ,  1.4424335 , ...,  0.17926188,\n",
       "        -0.03232881,  0.58735865],\n",
       "       [ 1.2289163 ,  0.6097862 ,  1.0696971 , ...,  0.06648731,\n",
       "         0.18469982,  0.51522267],\n",
       "       ...,\n",
       "       [ 0.22366384,  1.1502502 ,  0.8767188 , ...,  0.27784175,\n",
       "         0.36527306,  0.8861254 ],\n",
       "       [ 0.6626982 ,  0.7835271 ,  1.2358161 , ...,  0.20994337,\n",
       "         0.35687056,  0.46137583],\n",
       "       [ 0.34324738,  0.5640084 ,  0.7523655 , ...,  0.09359919,\n",
       "         0.20470257,  0.328089  ]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.to('cpu').detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "STAligner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
